# Идеи
1. Объединить два цикла в `base.py` и убрать промежуточный список файлов `file_s_paths`,
    тогда можно сразу обрабатывать файлы в первом цикле без накопления списка
```python
# Сейчас все выглядит как
file_s_paths = []
for dirpath, _, files in os.walk(folder):
    for file in files:
        ...
            file_s_paths.append(file)
for file in file_s_paths:
    ... # обработка
```
> Если файлов 10 000+ то в этом есть смысл, но если 8-10 то можно оставить

2. Попробовать многопоточность или мультипроцессинг для параллельной обработки файлов,
   cейчас каждый файл обрабатывается последовательно и если файлов 100+ то обработка каждого файла занимает значительное время
> Основное время уходит не на чтение файлов через `ET.parse`,
> а на конструирование `xmlTag` для всех узлов (объекты, Dict2Object + рекурсивная обработка)
> и рекурсивный поиск `find_objects` - это CPU-bound, а не I/O-bound.
> Как я знаю в Python многопоточность (threading) не ускорит CPU-bound задачи из-за GIL.
> Для CPU-bound нужна многопроцессная обработка (multiprocessing), каждый процесс на отдельном ядре.
> Например если использовать `multiprocessing.Pool` и распределить файлы по ядрам:
```python
from multiprocessing import Pool

def process_file(file_path):
    # весь код обработки файла
    ...
    return result

with Pool(processes=4) as pool:  # например, 4 ядра
    results = pool.map(process_file, list_of_files)
```
> Тут каждый файл обрабатывается параллельно на отдельном ядре и тут можно получить х3-х4 ускорение на 4-х ядерной машине,
> но есть трабл что объекты `xmlTag` не сериализуемы прямо в `multiprocessing` и надо возвращать чистые dict или JSON-совместимые данные,
> вместе с тем нужно аккуратно объединять результаты в `search_tool.container`
>> Мне кажется реально больное место это объектная модель и поиск, но поставить мультипроцессинг кайфы
---
# Профайлинг текущей реализации
`223054 function calls (187249 primitive calls) in 0.106 seconds` 
| №  | ncalls     | tottime | percall | cumtime | percall | filename:lineno(function) |
|----|-----------|---------|--------|---------|--------|----------------------------|
| 1  | 21/1      | 0.000   | 0.000  | 0.106   | 0.106  | {built-in method builtins.exec} |
| 2  | 1         | 0.000   | 0.000  | 0.106   | 0.106  | base.py:1(<module>) |
| 3  | 1         | 0.001   | 0.001  | 0.095   | 0.095  | base.py:13(main) |
| 4  | 7867/8    | 0.004   | 0.000  | 0.036   | 0.004  | xml_reader.py:135(find_objects) |
| 5  | 7867/8    | 0.003   | 0.000  | 0.034   | 0.004  | xml_reader.py:95(__init__) |
| 6  | 7867/8    | 0.020   | 0.000  | 0.034   | 0.004  | xml_reader.py:57(__init__) |
| 7  | 7867/8    | 0.005   | 0.000  | 0.034   | 0.004  | xml_reader.py:34(child_mapper) |
| 8  | 7867      | 0.020   | 0.000  | 0.031   | 0.000  | xml_reader.py:102(_search_condition_) |
| 9  | 37/6      | 0.000   | 0.000  | 0.014   | 0.002  | <frozen importlib._bootstrap>:1360(_find_and_load) |
| 10 | 37/6      | 0.000   | 0.000  | 0.013   | 0.002  | <frozen importlib._bootstrap>:1308(_find_and_load_unlocked) |
| 11 | 28/8      | 0.000   | 0.000  | 0.013   | 0.002  | <frozen importlib._bootstrap>:914(_load_unlocked) |
| 12 | 19/8      | 0.000   | 0.000  | 0.013   | 0.002  | <frozen importlib._bootstrap_external>:753(exec_module) |
| 13 | 8         | 0.000   | 0.000  | 0.012   | 0.001  | /usr/lib/python3.14/xml/etree/ElementTree.py:1204(parse) |
| 14 | 8         | 0.001   | 0.000  | 0.012   | 0.001  | /usr/lib/python3.14/xml/etree/ElementTree.py:553(parse) |
| 15 | 78/13     | 0.000   | 0.000  | 0.011   | 0.001  | <frozen importlib._bootstrap>:483(_call_with_frames_removed) |
| 16 | 8         | 0.011   | 0.001  | 0.011   | 0.001  | {method '_parse_whole' of 'xml.etree.ElementTree.XMLParser' objects} |
| 17 | 3989/8    | 0.009   | 0.000  | 0.010   | 0.001  | xml_reader.py:5(recursive_parse) |
| 18 | 62879     | 0.006   | 0.000  | 0.006   | 0.000  | {built-in method builtins.isinstance} |
| 19 | 27038     | 0.004   | 0.000  | 0.004   | 0.000  | {method 'keys' of 'dict' objects} |
| 20 | 31567     | 0.003   | 0.000  | 0.003   | 0.000  | {built-in method builtins.hasattr} |
---
# Комментарий к профайлингу
- Работает быстро
- Очень болтливая
- Избыток объектной и рекурсивной логики
- На обработку 1 XML файла приходится ~6000 узлов
- Каждый узел превращается в объект
- Каждый объект учавствует в поиске
- На дистанции плохо масштабируется (при х10 XML станет x10 медленее)
- CPU-bound, а не I/O-bound
- Есть явные источники нагрузки
  - `xmlTag.__init__` + `Dict2Object` (№5, 6, 7)
      - `__annotations__`
      - `hasattr`
      - `isinstance`
      - `dict.keys`
      - кастомные мапперы
      - все это затратно когда вызывается по 6000+ раз
  - `__search_condition__` (№8)
  ```python
      # Вызывается 7867 раз
      for attr, val in self.attribs.items():
          ...
  ```
---
# Предложения
1. Не строить объективное дерево целиком
> Вместо ElementTree -> dict -> xmlTag -> рекурсивный поиск искать объекты напрямую по ElementTree без промежуточного dict
```python
def find_objects_etree(elem):
    if elem.tag == 'init' and 'target' in elem.attrib:
        ...
    for child in elem:
        yield from find_objects_etree(child)
```
2. Сделать отложенное создание `xmlTag` только для найденных узлов, а не для всех
3. Упростить `__search_condition__`
> Убрать циклы self.attribs
```python
if isinstance(search_attribs, dict):
    return self.tag == object_name and any(
        self.attribs.get(k) in v
        for k, v in search_attribs.items()
    )
```
4. Скорректировать `MnemoSettings._sorted_container_()`
```python
# Объекты имеют иерархию в данных (pl1 -> pl2 -> ...)
# Значения фиксированной длинны (00, 01, ...)
# Можно сказать подготовленны для лексиграфической сортировки

# Можешь помочь простое использование sorted с ключем
sorted(self.container, keys=...)

# Без рекурсии
# Без временных контейнеров
# Без индексов
# Без побочных эффектов

# Например так
def _sorted_container_(self) -> list[dict[str, str]]:
    return sorted(
        self.container,
        key=lambda d: (d['pl1'], d['pl2'], d['pl3'], d['pl4'])
    )
```
# Заключение
## Нужна оптимизация самой обработки (мастхев)
Проблема: 
- создаём `xmlTag` для всех узлов и рекурсивно ищем объекты

Решение:
- не строить весь объектный слой, а искать нужные узлы на лету в ElementTree
- либо лениво создавать xmlTag только для найденных объектов.
```python
def find_targets_etree(root, target_attrs):
    for elem in root.iter():  # проход по всему дереву
        if elem.tag == 'init' and 'target' in elem.attrib:
            if elem.attrib['target'] in target_attrs:
                yield {
                    'uuid': elem.attrib.get('uuid'),
                    'target': elem.attrib['target'],
                    'value': elem.attrib.get('value')
                }
```
Результат: 
- должна исчезнуть львиная часть вызовов `xmlTag.__init__`
- убирается рекурсивный поиск `find_objects`
- получаешь ускорение без параллели
## Мультипроцессинг (вишенка на торте)
- Если файлов 100+ и каждый файл большой, тогда используем multiprocessing
- Важно: возвращаем dict/json, а не xmlTag объекты
- После этого объединяем контейнеры и делаем сортировку
## Мелкие оптимизации 
- Объединение циклов в base.py почти не то что бы нужно
- Можно улучшить `_search_condition_` и `_sorted_container_`, но реально выигрыш там небольшой
